In this section we'll explain our work on generation of binary trees
at random. We're interested to setup a simulation to study the means
of the number of leaves in trees with $n$ nodes and comparing the
result of the simulation against theoretical results.

In order to do this we've implemented an algorithm to generate binary
trees: it consume $n \in \mathbb{N} $ and produce a binary tree with
$n$ nodes.

We've repeated the application of that algorithm $k (>>
n)$ times in order to check if the algorithm is an \emph{uniform}
binary tree generator, that is, if the generator would be perfect,
each tree with $n$ nodes should have $ \frac{1}{
  \frac{1}{n+1}{{2n}\choose{n}} } $ probability to be generated.

The last point of our work is to check a theoretical result about the
mean of number of leaves among binary trees with $n$ nodes.


\section{Atkinson and Sack algorithm}
Describe briefly the algorithm here.

\section{Implementation using R}

\begin{lstlisting}
  generate.tree <- function(number_of_nodes){
    word_dimension <- 2 * number_of_nodes    
    universe <- 1:word_dimension
    sample <- sample(universe, size=number_of_nodes)
    w = rep(0, word_dimension)
    for (i in 1:word_dimension) {
      w[i] <- ifelse(any(sample == i), 1, -1)
    }    
    phi=phi(w)
    list(word=w, phi=phi, as_brackets = brackets_of_word(phi))
  }

  split.word <- function(w){
    if(length(w) == 0){
      return(list(u=c(), v=c()))
    }    
    u_index_set <- 1:match(0, cumsum(w))
    list(u=w[u_index_set], v=w[-u_index_set])
  }

  phi <- function(w){
    if(length(w) == 0){
      return(w)
    }    
    split <- split.word(w)     
    if(all(cumsum(split$u) > -1)){
      return (c(split$u, phi(split$v)))
    }
    else{
      t = split$u[-c(1, length(split$u))]
      return (c(1, phi(split$v), -1, -t))
    }
  }
\end{lstlisting}

\section{Checking randomness}

In order to establish if the algorithm is an \emph{uniform random}
generator, we perform a $\chi^2$ test on the generated trees. We've
implemented that process in R and we're going to comment the result
obtained.

In \autoref{table:p-values-per-nodes} we report the $p$-values
obtained performing a simulation on trees with $4,5,6,8,10$ nodes
(in columns) and for each dimension, we build $1000, 2000, 5000,
10000, 20000, 50000$ trees (in rows). In order to be considered an
\emph{uniform random} generator, each $p$-value $v$ should be $.1
\leq v\ \leq .9$.
\begin{table}[ht]
  \begin{center}
    \begin{tabular}{rrrrrr}
      \hline
      & 4 & 5 & 6 & 8 & 10 \\ 
      \hline
      1000 & 0.60 & 0.85 & 0.54 & 1.00 & 1.00 \\ 
      2000 & 0.99 & 0.98 & 0.13 & 1.00 & 1.00 \\ 
      5000 & 0.36 & 0.85 & 0.28 & 1.00 & 1.00 \\ 
      10000 & 0.69 & 0.73 & 0.11 & 0.65 & 1.00 \\ 
      20000 & 0.63 & 0.23 & 0.50 & 0.16 & 1.00 \\ 
      50000 & 0.09 & 0.74 & 0.63 & 0.90 & 1.00 \\ 
      \hline
    \end{tabular}
    \caption{$p$-values per trees and nodes}
    \label{table:p-values-per-nodes}
  \end{center}
\end{table}
Our simulation is quite good, there are two strange $p$-values for
dimension $2000$ and trees $4,5$ where we find $.99$ and $.98$. Maybe
the chance has played its role at the running time. Instead, the cell
containing $1$s means that the number of trees isn't sufficient to
perform a $\chi^2$ test (there are $16796$ different trees with $10$
nodes, with all simulated dimension isn't possible to test
randomness).

In table \autoref{table:empirical-trees-per-nodes} we report the
empirical number of trees calculated for trees with some nodes, each a
different number of times (as in the case above).
% latex table generated in R 2.15.1 by xtable 1.5-6 package
% Sun Dec 23 17:49:56 2012
\begin{table}[ht]
  \begin{center}
    \begin{tabular}{rrrrrr}
      \hline
      & 4 & 5 & 6 & 8 & 10 \\ 
      \hline
      1000 & 11.08 & 31.69 & 128.86 & 1456.74 & 16770.17 \\ 
      2000 & 4.39 & 24.36 & 149.75 & 1454.88 & 17046.66 \\ 
      5000 & 14.18 & 31.62 & 140.13 & 1378.37 & 16478.72 \\ 
      10000 & 10.09 & 35.05 & 151.54 & 1414.26 & 17028.12 \\ 
      20000 & 10.75 & 47.34 & 130.37 & 1483.03 & 16813.47 \\ 
      50000 & 20.26 & 34.83 & 125.10 & 1359.54 & 16778.21 \\ 
      \hline
    \end{tabular}
    \caption{Empirical number of trees per nodes}
    \label{table:empirical-trees-per-nodes}
  \end{center}
\end{table}
We can see a correspondence of ``strange'' values in $p$-values table
and in the empirical number of trees table: where the $p$-values $v$
indicate a non random sequence we've a corresponding empirical value
very different respect the others in the same column.

It is possible to compare the values contained in table
\autoref{table:empirical-trees-per-nodes} with those (theoretically
correct) contained in \autoref{table:catalan-numbers}.
\begin{table}[ht]
  \begin{center}
    \begin{tabular}{rrrrrr}
      \hline
      number of nodes & 4 & 5 & 6 & 8 & 10 \\ 
      number of trees & 14 & 42 & 132 & 1430 & 16796 \\ 
      \hline
    \end{tabular}
    \caption{Number of trees per nodes}
    \label{table:catalan-numbers}
  \end{center}
\end{table}

\section{Means of leaves and heights}

In this section we study the means of the number of leaves and of
heights of all different binary trees with $n$ nodes.

From theory we know that the mean of leaves of trees with $n$ nodes
is:
\begin{displaymath}
  \frac{n\,\left( n+1\right)  }{2\,\left( 2\,n-1\right) }
\end{displaymath}
Using Maxima to have the expacted means for some nodes dimensions:

\noindent
%%%%%%%%%%%%%%%
%%% INPUT:
\begin{minipage}[t]{8ex}{\color{red}\bf
\begin{verbatim}
(%i178) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
fpprintprec:4$
leaves(n):=(n*(n+1))/(2*(2*n-1));
combineResult(n):=[n,leaves(n)]$
map(combineResult, makelist(n,n,1,10)),numer;
\end{verbatim}}
\end{minipage}
%%% OUTPUT:
\definecolor{labelcolor}{RGB}{100,0,0}
\begin{math}\displaystyle
\parbox{8ex}{\color{labelcolor}(\%o179) }
\mathrm{leaves}\left( n\right) :=\frac{n\,\left( n+1\right)
}{2\,\left( 2\,n-1\right) }
\end{math}\\
\begin{math}\displaystyle
\parbox{8ex}{\color{labelcolor}(\%o181) }
[[1,1],[2,1],[3,1.2],[4,1.429],[5,1.667],[6,1.909],[7,2.154],[8,2.4],
[9,2.647],[10,2.895]]
\end{math}
%%%%%%%%%%%%%%%

\begin{table}[!ht]
  \label{table:means-of-leaves-height}
  \begin{center}
    \rotatebox{90}{
      \begin{tabular}{rrrrrrr}
        \hline
        & nodes & dimensions & theo.mean.leaves & theo.mean.height & emp.mean.leaves & emp.mean.height \\ 
        \hline
         &   3 & 100 & 1.20 & 2.80 & 1.16 & 2.84 \\ 
         &   4 & 200 & 1.43 & 3.57 & 1.35 & 3.65 \\ 
         &   5 & 300 & 1.67 & 4.24 & 1.70 & 4.23 \\ 
         &   6 & 1000 & 1.91 & 4.88 & 1.91 & 4.87 \\ 
         &   7 & 10000 & 2.15 & 5.47 & 2.15 & 5.46 \\ 
         &   8 & 10000 & 2.40 & 6.03 & 2.41 & 6.02 \\ 
         &   9 & 50000 & 2.65 & 6.56 & 2.65 & 6.56 \\ 
         &  10 & 100000 & 2.89 & 7.07 & 2.90 & 7.07 \\ 
        \hline
      \end{tabular}
    }
  \end{center}
  \caption{Theoretical and empirical means for leaves and height}
\end{table}

In \autoref{table:means-of-leaves-height} we report the results
obtained with our implementation in R: the second column report the
number of trees generated with the correspondent number of nodes.

\section{Standardized means and asymptotic distributions}

In this section we study the asymptotic distribution of the means for
the leaves and heights of trees with $n$ nodes. We use the result of
the \emph{Central Limit Theorem} to check if the two means under study
behave like a normal distrubution in repeated sampling.

Each of the following plots are obtained repeating 1000 times the
generation of 500 trees each with 5 nodes. In each plot the red dotted
curve is the normal distribution (out ``target''), while the blue
continue curve is the inferred distribution.

In \autoref{fig:leaves-mean-distribution} we report the standardized
mean of leaves.
\begin{figure}[htb]
  \centering
  \includegraphics[height=13cm,
  width=13cm]{pictures/repeated-sampling-leaves-mean.pdf}
  \caption{Standardized leaves mean distribution}
  \label{fig:leaves-mean-distribution}
\end{figure}

In \autoref{fig:height-mean-distribution} we report the standardized
mean of leaves.
\begin{figure}[htb]
  \centering
  \includegraphics[height=13cm,
  width=13cm]{pictures/repeated-sampling-height-mean.pdf}
  \caption{Standardized height mean distribution}
  \label{fig:height-mean-distribution}
\end{figure}

\section{Drawing trees}

Just for fun, our implementation draw all different trees with $n$
nodes (this implementation is done in OCaml). In
\autoref{fig:binary-trees-with-four-nodes} we report the image with
all binary trees with $4$ nodes.
\begin{figure}[htb]
  \centering
  \rotatebox{90}{
    \includegraphics{pictures/binary-trees-with-four-nodes.png}
  }
  \caption{Binary trees with four nodes}
  \label{fig:binary-trees-with-four-nodes}
\end{figure}
